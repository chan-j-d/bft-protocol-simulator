{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0927668-2998-44c9-bad3-b79c2f0ca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import gamma\n",
    "import re\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, List, Callable, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082cfd1-2f02-424a-995a-eb234b53fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings\n",
    "num_runs = 1\n",
    "starting_seed = 0\n",
    "seed_multiplier = 100\n",
    "\n",
    "# Validator settings\n",
    "num_nodes = 32\n",
    "num_consensus = 2000\n",
    "base_time_limit = 10000\n",
    "node_processing_distribution = \"exp\"\n",
    "node_processing_parameters = [3]\n",
    "consensus_protocol = \"IBFT\"\n",
    "\n",
    "## Fault settings\n",
    "num_faults = 1\n",
    "fault_type = \"UR\"\n",
    "fault_parameters = []\n",
    "\n",
    "# Network settings\n",
    "## Switch settings\n",
    "switch_processing_distribution = \"degen\"\n",
    "switch_processing_parameters = [0]\n",
    "message_channel_success_rate = 1\n",
    "\n",
    "network_type = \"Clique\"\n",
    "network_parameters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER_REGEX = r'json_n(.+)_btl(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)'\n",
    "\n",
    "def get_num_nodes(filename: str) -> int:\n",
    "    return int(re.match(RESULTS_FOLDER_REGEX, filename).group(1))\n",
    "\n",
    "def get_btl(filename: str) -> float:\n",
    "    return float(re.match(RESULTS_FOLDER_REGEX, filename).group(2))\n",
    "\n",
    "def get_topology(filename: str) -> str:\n",
    "    return re.match(RESULTS_FOLDER_REGEX, filename).group(5)\n",
    "\n",
    "def get_protocol(filename: str) -> str:\n",
    "    return re.match(RESULTS_FOLDER_REGEX, filename).group(9)\n",
    "\n",
    "def get_num_faults(filename: str) -> int:\n",
    "    return int(re.match(RESULTS_FOLDER_REGEX, filename).group(10))\n",
    "\n",
    "def get_node_distribution(filename: str) -> str:\n",
    "    return re.match(RESULTS_FOLDER_REGEX, filename).group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de37679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More utility methods for analysis\n",
    "def get_minima(series: pd.Series):\n",
    "    return series[(series < series.shift(1)) & (series < series.shift(-1))].iloc[0]\n",
    "\n",
    "def get_minima_index(series: pd.Series):\n",
    "    return series[(series < series.shift(1)) & (series < series.shift(-1))].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d17a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_VALIDATOR_FILENAME = \"validator_results.json\"\n",
    "RESULTS_FOLDER = \"results\"\n",
    "FASTEST_MESSAGE_MAP = \"fastestMessageCountMap\"\n",
    "REMAINDER_MESSAGE_MAP = \"remainderMessageCountMap\"\n",
    "FASTEST_TIME_MAP = \"fastestStateTimeMap\"\n",
    "REMAINDER_TIME_MAP = \"remainderStateTimeMap\"\n",
    "PREPARED = \"PREPARED\"\n",
    "PREPREPARED = \"PREPREPARED\"\n",
    "COMMIT = \"COMMIT\"\n",
    "SYNC = \"SYNC\"\n",
    "ROUND_CHANGE = \"ROUND_CHANGE\"\n",
    "TOTAL_TIME_KEY = \"t_total_fastest\"\n",
    "RC_PROB = \"RC_PROB\"\n",
    "NEW_ROUND = \"NEW_ROUND\"\n",
    "PRE_PREPARED = \"PRE_PREPARED\"\n",
    "LAMBDA_FASTEST = \"lambda_fastest\"\n",
    "L_FASTEST = \"L_fastest\"\n",
    "L_REMAINDER = \"L_remainder\"\n",
    "\n",
    "NEW_VIEW = \"NEW_VIEW\"\n",
    "PREPARE = \"PREPARE\"\n",
    "PRE_COMMIT = \"PRE_COMMIT\"\n",
    "DECIDE = \"DECIDE\"\n",
    "COMMIT = \"COMMIT\"\n",
    "\n",
    "IBFT_STATES = [NEW_ROUND, PRE_PREPARED, PREPARED, ROUND_CHANGE]\n",
    "HS_STATES = [PREPARE, PRE_COMMIT, COMMIT, DECIDE]\n",
    "PROTOCOL_NAME_STATE_MAP = {\"hs\": HS_STATES, \"ibft\": IBFT_STATES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_RESULTS_DIRECTORY = \"results/\"\n",
    "\n",
    "def get_num_faults_data(num_faults: int, name: str, dir:str=DEFAULT_RESULTS_DIRECTORY) -> pd.Series:\n",
    "    return get_fn_data(num_nodes, network_type, consensus_protocol, num_faults, node_processing_distribution, lambda json: json[TOTAL_TIME_KEY], name, dir=dir)\n",
    "\n",
    "def get_fn_data(num_nodes: int, topology: str, protocol: str, num_faults: int, dist: str, fn: Callable[[str], Any], name: str, dir:str=DEFAULT_RESULTS_DIRECTORY) -> pd.Series:\n",
    "    results_lst = os.listdir(dir)\n",
    "    index = []\n",
    "    lst = []\n",
    "    for result_filename in results_lst:\n",
    "        matcher = re.match(RESULTS_FOLDER_REGEX, result_filename)\n",
    "        if matcher == None: \n",
    "            continue\n",
    "        run_num_nodes = get_num_nodes(result_filename) \n",
    "        run_base_time_limit = get_btl(result_filename) \n",
    "        run_topology = get_topology(result_filename) \n",
    "        run_protocol = get_protocol(result_filename) \n",
    "        run_num_faults = get_num_faults(result_filename)\n",
    "        run_dist = get_node_distribution(result_filename)\n",
    " \n",
    "        if run_protocol != protocol.lower() or run_num_nodes != num_nodes or run_num_faults != num_faults or run_dist != dist \\\n",
    "                or run_topology != topology.lower():\n",
    "            continue\n",
    " \n",
    "        index.append(run_base_time_limit)\n",
    "        with open(os.path.join(dir, result_filename, RESULTS_VALIDATOR_FILENAME), \"r\") as json_result:\n",
    "            result_json = json.load(json_result)\n",
    "            lst.append(fn(result_json))\n",
    "    return pd.Series(lst, index=index, name=name).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protocol comparison\n",
    "f = 4\n",
    "n1 = \"random_perm_\" + str(f) + \"_faults\"\n",
    "n2 = \"random_leader_\" + str(f) + \"_faults\"\n",
    "s1 = get_fn_data(16, \"clique\", \"ibft\", f, \"exp\", lambda json: json[TOTAL_TIME_KEY], n1)\n",
    "s2 = get_fn_data(16, \"clique\", \"ibft\", f, \"exp\", lambda json: json[TOTAL_TIME_KEY], n2, dir=\"results/ibft_random_leader/\")\n",
    "df = pd.DataFrame([s1, s2]).transpose()\n",
    "\n",
    "n = 16\n",
    "\n",
    "x0 = 15\n",
    "def random_leader_line(r: float):\n",
    "    gradient = r / (1 - 2 * r) \n",
    "    intercept = df[n2][x0] - x0 * gradient\n",
    "    return lambda x : intercept + gradient * x\n",
    "\n",
    "def random_perm_line(r: float):\n",
    "    gradient = r / (1 - 2 * r) \n",
    "    gradient = (r + 2 * r * (r - (1 / n)) + 4 * r * (r - 1 / n) * (r - 2 / n)) \n",
    "    intercept = df[n1][x0] - x0 * gradient\n",
    "    return lambda x : intercept + gradient * x\n",
    "\n",
    "df[\"random_leader_line\"] = df.index.map(random_leader_line(f / 16))\n",
    "df[\"random_perm_line\"] = df.index.map(random_perm_line(f / n))\n",
    "df.plot(style=\".-\", ylabel=\"time to consensus\", xlabel=\"base time limit\", figsize=(10, 5), title=\"Random leader vs Random Permutation (with \" + str(f) + \" faults)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c82b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_num_faults = [0, 2, 4, 8]\n",
    "df = pd.DataFrame({str(x) + \"_fault\": get_num_faults_data(x, str(x) + \"_fault\") for x in lst_num_faults})\n",
    "df = df.interpolate(method=\"linear\")\n",
    "df.plot(grid=True, style=\".-\", xlabel=\"base_time_limit\", ylabel=\"time_to_consensus\", title=consensus_protocol + \" simulation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1abb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradients\n",
    "# 0: 0, 1: 0.05, 2: 0.125, 3: 0.225\n",
    "# gradients = {0: 0, 1: 0.0625, 2: 0.142, 3: 0.245, 4: 0.383}\n",
    "gradients = {0: 0, 1: 0.0714, 2: 0.167, 3: 0.3, 4: 0.5}\n",
    "names = [str(x) + \"_fault\" for x in lst_num_faults]\n",
    "minima = [get_minima(df[name]) for name in names]\n",
    "minima_index = [get_minima_index(df[name]) for name in names]\n",
    "minima, minima_index\n",
    "\n",
    "def get_ibft_right_line(num_faults: int):\n",
    "    index = lst_num_faults.index(num_faults)\n",
    "    return lambda t : minima[index] + (t - minima_index[index]) * gradients[num_faults]\n",
    "\n",
    "df[\"test\"] = df.index.map(get_ibft_right_line(3))\n",
    "df.plot(style=\".-\", grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IBFT WORK\n",
    "def get_round_change_probs(num_faults: int, name: str):\n",
    "    return get_fn_data(num_nodes, network_type, \"ibft\", num_faults, node_processing_distribution, \n",
    "                       lambda json: min(json[FASTEST_MESSAGE_MAP][PREPREPARED] - 1, 1), name)\n",
    "\n",
    "###\n",
    "def time5(t: float, n: int, f: int, mu: float) -> float:\n",
    "    p = get_success_probability(t, n, f, mu) \n",
    "    r = f / n\n",
    "    t_fault_first = (r + 2 * r * (r - (1 / n)) + 4 * r * (r - 1 / n) * (r - 2 / n)) * t \n",
    "\n",
    "    max_f = (n - 1) // 3\n",
    "\n",
    "    t_working_fail = (n - f) / n * (1 - p) * (t + t_fault_first * 2 + ((max_f - f + 1) / mu) + (3 * n - 2 * f - max_f) / mu + (n - f) / mu * (1 - r)) # 3.1 is first round new round penalty, additional n - f is penalty approx of changing halfway through\n",
    "    t_fault_first += r * ((2 * n - max_f - f) / mu) \n",
    "    t_working_success = (n - f) / n * p * min(t, ibft_te2e(n, mu) - f / mu)\n",
    "    return t_fault_first + t_working_fail + t_working_success\n",
    "\n",
    "def ibft_te2e(n: int, mu: float):\n",
    "    return (10 * n + 2) * (2 * n + 1) / (mu * (7 + 11 * n - np.sqrt(37 + 70 * n + n * 2)))\n",
    "\n",
    "def get_success_mean(n: int, f: int, mu: float) -> float:\n",
    "    max_f = (n - 1) // 3\n",
    "    return ((max_f - f) / 2 + 2 * n - max_f - f) / mu\n",
    "    # return (2 * n - max_f - f) / mu\n",
    "\n",
    "def get_success_stdev(n: int, f: int, mu: float, t: float) -> float:\n",
    "    max_f = (n - 1) // 3\n",
    "    return np.sqrt((1 / (mu ** 2)) * (2 * n - max_f - f + (max_f - f) / 2) * (2 + 1 / (n - f)))\n",
    "    # return np.sqrt((1 / (mu ** 2)) * (2 * n - max_f - f) * (2 + 1 / (n - f)))\n",
    "\n",
    "def get_success_probability(t: float, n: int, f: int, mu: float) -> float:\n",
    "    return norm.cdf(t, loc=get_success_mean(n, f, mu), scale=get_success_stdev(n, f, mu, t))\n",
    "\n",
    "def ibft_reco(n: int, f: int, mu: float, sigma: float):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = ((max_f - f) / 2 + 2 * n - max_f - f)\n",
    "    return m * mu + sigma * np.sqrt(m * (2 + 1 / (n - f))) * 3 \n",
    "\n",
    "def ibft_test(f: int):\n",
    "    round_change_probs = get_round_change_probs(f, \"round_change_prob_\" + str(f)) \n",
    "    consensus_times = get_num_faults_data(f, \"faults_\" + str(f))\n",
    "\n",
    "    df = pd.DataFrame({\"RC_PROB\": round_change_probs, TOTAL_TIME_KEY: consensus_times})\n",
    "    df[\"new_prob\"] = df.index.map(lambda t: (num_nodes - f) / num_nodes - (num_nodes - f) / num_nodes * norm.cdf(t, loc=get_success_mean(num_nodes, f, 3), scale=get_success_stdev(num_nodes, f, 3, t)))\n",
    "    # df[[\"RC_PROB\", \"new_prob\"]].plot(style=\".-\", grid=True, xlabel=\"base time limit\", ylabel=\"probability of round change\")\n",
    "    df[\"prediction\"] = df.index.map(lambda t: time5(t, num_nodes, f, 3))\n",
    "    df[[TOTAL_TIME_KEY, \"prediction\"]].plot(grid=True, style=\".-\", title=\"Consensus time vs prediction with \" + str(f) + \" faults\", figsize=(10, 5))\n",
    "    plt.axvline(ibft_reco(num_nodes, f, 1/3, 1/3))\n",
    "    plt.show()\n",
    "\n",
    "# for i in [0, 1, 2, 3, 4]:\n",
    "for i in [0, 2, 4, 8]:\n",
    "    f=i\n",
    "    ibft_test(i)\n",
    "# df.new_prob.plot(style=\".-\", grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd495c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hs_time(n, t, mu, te2e):\n",
    "    max_f = (n - 1) // 3\n",
    "    p = gamma.cdf(t, 4 * n + 3 - max_f, scale=(1/mu))\n",
    "    # print(p)\n",
    "    t_fail = (1 - p) * t \n",
    "    # p2 = gamma.cdf(2 * t, 4 * n + 3  - max_f, scale=(1/mu))\n",
    "    # t_fail += (1 - p) * (1 - p2) * (2 * t)\n",
    "    t_succeed = 1 * te2e\n",
    "    # p3 = gamma.cdf(4 * t, 4 * n + 3 - f, scale=(1/mu))\n",
    "    # t_fail += (1 - p) * (1 - p2) * (1 - p3) * (4 * t)\n",
    "    t_total = t_fail + t_succeed\n",
    "    return t_total\n",
    "\n",
    "def hs_time_fault(n, t, rate, f):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = (4 * n + 4 - max_f - 3 * f) \n",
    "    te2e = m / rate \n",
    "\n",
    "    p_fault = f / n\n",
    "    t_penalty_first_fault = 0 \n",
    "    for i in range(1, f + 1):\n",
    "        t_penalty_first_fault += p_fault ** i * t * (2 ** (i - 1)) \n",
    "\n",
    "    p = gamma.cdf(t, m - 1, scale=(1/rate))\n",
    "    t_fail = (1 - p) * (t + t_penalty_first_fault * 2)\n",
    "    t_total = t_fail * (n - f) / n + te2e \n",
    "\n",
    "    # print(t_total, t_fail, t_succeed, t_penalty_first_fault)\n",
    "    return t_total + t_penalty_first_fault\n",
    "\n",
    "# Testing recommendation\n",
    "def hs_reco(n, f, mu, sigma):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    sigma_m = np.sqrt(m) * sigma \n",
    "    return (m * mu + 3 * sigma_m) \n",
    "\n",
    "def range_max_estimate(n, mu):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f \n",
    "    return int(m * mu * 1.75)\n",
    "\n",
    "def range_min_estimate(n, mu):\n",
    "    # return int(range_max_estimate(n, mu) / 1.75 / 2)\n",
    "    return 0\n",
    "\n",
    "def get_hs_minima(n, mu, frac):\n",
    "    max_f = (n - 1) // 3\n",
    "    f = int(frac * max_f)\n",
    "    top = range_max_estimate(n, mu)\n",
    "    bot = range_min_estimate(n, mu)\n",
    "    if frac == 0:\n",
    "        return hs_time_fault(n, top, 1/mu, f) \n",
    "    rg = [bot + (top - bot) / 1000 * i for i in range(1000)] \n",
    "    lst = [hs_time_fault(n, t, 1/mu, max_f * frac // 2) for t in rg] \n",
    "    s = pd.Series(lst, index=rg)\n",
    "    temp = s[(s < s.shift(1)) & (s < s.shift(-1))]\n",
    "    return temp.iloc[0]\n",
    "\n",
    "def get_num_faults_from_frac(n, frac):\n",
    "    return int((n - 1) // 3 * frac / 2)\n",
    "\n",
    "def hs_estimate_left_line(n, f, mu, t):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    te2e = m * mu\n",
    "    # gradient = n / (n - 2 * f) \n",
    "    # return te2e + gradient * t\n",
    "    one = te2e + sum((f / n) ** (i - 1) * t * 2 ** (i - 1) for i in range(1, f + 1))\n",
    "    one *= f / n\n",
    "    two = te2e + sum((f / n) ** i * (t * 2 ** i) for i in range(f + 1))\n",
    "    two *= (n - f) / n\n",
    "    return one + two\n",
    "\n",
    "\n",
    "def hs_estimate_right_line(n, f, mu, t):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    mean = m * mu\n",
    "    gradient = f / (n - 2 * f)\n",
    "    return mean + gradient * t\n",
    "\n",
    "def full_estimate(n, f, mu, sigma, t):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    mean = m * mu\n",
    "    sigma_m = np.sqrt(m) * sigma\n",
    "    bot_boundary = mean - 2 * sigma_m\n",
    "    top_boundary = mean + 2 * sigma_m\n",
    "    y1 = hs_estimate_left_line(n, f, mu, bot_boundary)\n",
    "    y2 = hs_estimate_right_line(n, f, mu, top_boundary)\n",
    "    if t > top_boundary:\n",
    "        return hs_estimate_right_line(n, f, mu, t)\n",
    "    elif t < bot_boundary:\n",
    "        return hs_estimate_left_line(n, f, mu, t)\n",
    "    else:\n",
    "        gradient = (y2 - y1) / (top_boundary - bot_boundary)\n",
    "        intercept = y2 - gradient * top_boundary\n",
    "        return gradient * t + intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc509c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [8, 12, 16, 32, 48, 64, 128, 256, 512, 1024]\n",
    "max_fault = pd.Series(index, index=index).apply(lambda n: get_hs_minima(n, 1/3, 1))\n",
    "no_fault = pd.Series(index, index=index).apply(lambda n: get_hs_minima(n, 1/3, 0))\n",
    "pd.DataFrame({\"Max faults\": max_fault, \"No faults\": no_fault}).plot(style=\".-\", title=\"HotStuff: Max number of faults - time to consensus with optimal BTL\", ylabel=\"Time to consensus\", xlabel=\"Number of validators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526deacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num_nodes = [16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "test_mu = 1 / 3\n",
    "test_num_faults = [2]\n",
    "df[\"prediction\"] = df.index.map(lambda t: hs_time_fault(num_nodes, t, node_processing_parameters[0], num_faults))\n",
    "# df[\"prediction\"] = df.index.map(lambda t: full_estimate(num_nodes, num_faults, 1/3, 1/3, t))\n",
    "df.plot(style=\".-\", figsize=(10, 5), grid=True, xlabel=\"base_time_limit\", ylabel=\"time per consensus\")\n",
    "\n",
    "# dic_model = {j: [get_minima(n, test_mu, j) for n in test_num_nodes] for j in test_num_faults}\n",
    "# dic_guess = {j: [hs_time_fault(n, hs_reco(n, get_num_faults_from_frac(n, j), test_mu, test_mu), 1/test_mu, get_num_faults_from_frac(n, j)) \n",
    "#                  for n in test_num_nodes] for j in test_num_faults}\n",
    "# df_model = pd.DataFrame(dic_model, index=test_num_nodes)\n",
    "# df_guess = pd.DataFrame(dic_guess, index=test_num_nodes)\n",
    "# (df_guess - df_model) / df_model\n",
    "\n",
    "plot_num_nodes = 2048\n",
    "rg = range(range_min_estimate(plot_num_nodes, test_mu), range_max_estimate(plot_num_nodes, test_mu))\n",
    "dic = {str(plot_num_nodes) + \"_\" + str(j): [hs_time_fault(plot_num_nodes, t, 1/test_mu, get_num_faults_from_frac(plot_num_nodes, j)) \n",
    "                               for t in range(range_min_estimate(plot_num_nodes, test_mu), range_max_estimate(plot_num_nodes, test_mu))]\n",
    "                               for j in test_num_faults}\n",
    "dic[\"test\"] = [full_estimate(plot_num_nodes, get_num_faults_from_frac(plot_num_nodes, 2), test_mu, test_mu, t) for t in rg]\n",
    "pd.DataFrame(dic, index=rg).plot( figsize=(15, 10), grid=True, ylabel=\"time to consensus\", xlabel=\"base time limit\")\n",
    "[plt.axvline(hs_reco(plot_num_nodes, get_num_faults_from_frac(plot_num_nodes, f), test_mu, test_mu)) for f in test_num_faults]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 20\n",
    "ibft_fn = lambda f: time5(t, 16, f, 3)\n",
    "hs_fn = lambda f: hs_time_fault(16, t, 3, f)\n",
    "\n",
    "index = pd.Series(range(6))\n",
    "ibft_pred = index.map(ibft_fn)\n",
    "hs_pred = index.map(hs_fn)\n",
    "pd.DataFrame({\"ibft\": ibft_pred, \"hs\": hs_pred}).plot(style=\".-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f666518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
