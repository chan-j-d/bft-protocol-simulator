{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0927668-2998-44c9-bad3-b79c2f0ca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import gamma\n",
    "from scipy.special import gamma as gamma_fn\n",
    "import re\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, List\n",
    "\n",
    "from distutils.dir_util import copy_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e5f9b-6cec-4545-84fc-a0ddedee2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_config_json import create_run_config_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_NAMES_KEY = \"stateTimeMap\"\n",
    "TOTAL_TIME_KEY = \"t_total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082cfd1-2f02-424a-995a-eb234b53fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings\n",
    "num_runs = 1\n",
    "starting_seed = 0\n",
    "seed_multiplier = 100\n",
    "\n",
    "# Validator settings\n",
    "num_nodes = 16\n",
    "num_consensus = 3000\n",
    "base_time_limit = 10000\n",
    "node_processing_distribution = \"exp\"\n",
    "node_processing_parameters = [3]\n",
    "consensus_protocol = \"IBFT\"\n",
    "\n",
    "## Fault settings\n",
    "num_faults = 3\n",
    "fault_type = \"UR\"\n",
    "fault_parameters = []\n",
    "\n",
    "# Network settings\n",
    "## Switch settings\n",
    "switch_processing_distribution = \"degen\"\n",
    "switch_processing_parameters = [0]\n",
    "message_channel_success_rate = 1\n",
    "\n",
    "network_type = \"Clique\"\n",
    "network_parameters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10833249-57c0-4bcb-a9cd-d16c12e38edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATOR_RESULTS_FILEPATH = \"../json\"\n",
    "RESULTS_DIRECTORY = \"json_n{num_nodes}_btl{base_time_limit:.1f}_{node_dist}_{node_params}_{topology}_{topo_params}_{switch_dist}_{switch_params}\" +  \\\n",
    "                    \"_{protocol}_{num_faults}_{fault_type}_{fault_params}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results_dic: dict): \n",
    "    processed_results_dic = {}\n",
    "    state_names = None\n",
    "    for var in results_dic.keys():\n",
    "        temp_dic = results_dic[var].copy()\n",
    "        if state_names == None:\n",
    "            state_names = temp_dic[STATE_NAMES_KEY].keys()\n",
    "        for key in temp_dic[STATE_NAMES_KEY].keys():\n",
    "            temp_dic[key] = temp_dic[STATE_NAMES_KEY][key]\n",
    "        del temp_dic[STATE_NAMES_KEY]\n",
    "        processed_results_dic[var] = temp_dic\n",
    "    return (processed_results_dic, state_names) \n",
    "\n",
    "def write_str_to_file(file_string: str, filename: str) -> None:\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(file_string)\n",
    "\n",
    "def run_and_save(run_config_dic: str, output_directory: str) -> None:\n",
    "    config_filename = \"config.json\"\n",
    "    write_str_to_file(run_config_dic, config_filename)\n",
    "\n",
    "    argument = \"py/\" + config_filename\n",
    "    ! (cd \"../\" && gradlew run --args={argument})\n",
    "    copy_tree(VALIDATOR_RESULTS_FILEPATH, output_directory)    \n",
    "\n",
    "def construct_results_directory(num_nodes: int, base_time_limit: float, \n",
    "                                node_processing_distribution: str, node_processing_parameters: List[float],\n",
    "                                topology: str, topo_params: List[int], switch_processing_distribution: str, switch_processing_parameters: List[float], \n",
    "                                protocol: str, num_faults: int, fault_type: str, fault_params: List[int]) -> str:\n",
    "    return RESULTS_DIRECTORY.format(num_nodes=num_nodes,  base_time_limit=base_time_limit, \n",
    "                                    node_dist=node_processing_distribution, node_params=node_processing_parameters, \n",
    "                                    topology=topology, topo_params=topo_params, switch_dist=switch_processing_distribution, switch_params=switch_processing_parameters, \n",
    "                                    protocol=protocol, num_faults=num_faults, fault_type=fault_type, fault_params=fault_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a54e6-268e-4a6e-ad6c-8ad589ceaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic = {}\n",
    "# for base_time_limit in [10, 10.5, 11, 11.5, 12, 12.5, 13, 13.5, 14, 14.5, 15, 15.5, 16, 16.5, 17, 17.5, 18, 18.5, 19, 19.5, 20, 20.5, 21, 21.5, 22, 22.5, 23, 24, 25, 26, 27, 28, 29, 30] + list(range(31, 51)): \n",
    "for base_time_limit in [20, 20.5, 21, 21.5, 22, 22.5, 23, 24, 25, 26, 27, 28, 29, 30] + list(range(31, 71)): \n",
    "# for base_time_limit in range(31, 51):\n",
    "# for base_time_limit in [5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5]:\n",
    "# for base_time_limit in [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5]:\n",
    "# for num_nodes in [4, 8, 16, 24, 32, 48, 64]:\n",
    "    json_obj = create_run_config_json(num_runs, starting_seed, seed_multiplier,\n",
    "                                      num_nodes, num_consensus, base_time_limit, \n",
    "                                      node_processing_distribution, node_processing_parameters, \n",
    "                                      consensus_protocol, num_faults, fault_type, fault_parameters,\n",
    "                                      switch_processing_distribution, switch_processing_parameters, \n",
    "                                      message_channel_success_rate, network_type, network_parameters)\n",
    "    run_and_save(json_obj, construct_results_directory(num_nodes, float(base_time_limit), \n",
    "                                                       node_processing_distribution, node_processing_parameters, \n",
    "                                                       network_type.lower(), network_parameters, \n",
    "                                                       switch_processing_distribution, switch_processing_parameters, \n",
    "                                                       consensus_protocol.lower(),\n",
    "                                                       num_faults, fault_type, fault_parameters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER_REGEX = r'json_n(.+)_btl(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)_(.+)'\n",
    "\n",
    "def get_num_nodes(filename: str) -> int:\n",
    "    return int(re.match(RESULTS_FOLDER_REGEX, filename).group(1))\n",
    "\n",
    "def get_btl(filename: str) -> float:\n",
    "    return float(re.match(RESULTS_FOLDER_REGEX, filename).group(2))\n",
    "\n",
    "def get_topology(filename: str) -> str:\n",
    "    return re.match(RESULTS_FOLDER_REGEX, filename).group(5)\n",
    "\n",
    "def get_protocol(filename: str) -> str:\n",
    "    return re.match(RESULTS_FOLDER_REGEX, filename).group(9)\n",
    "\n",
    "def get_num_faults(filename: str) -> int:\n",
    "    return int(re.match(RESULTS_FOLDER_REGEX, filename).group(10))\n",
    "\n",
    "def get_node_distribution(filename: str) -> str:\n",
    "    return re.match(RESULTS_FOLDER_REGEX, filename).group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d17a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_VALIDATOR_FILENAME = \"validator_results.json\"\n",
    "RESULTS_FOLDER = \"results\"\n",
    "FASTEST_MESSAGE_MAP = \"fastestMessageCountMap\"\n",
    "REMAINDER_MESSAGE_MAP = \"remainderMessageCountMap\"\n",
    "FASTEST_TIME_MAP = \"fastestStateTimeMap\"\n",
    "REMAINDER_TIME_MAP = \"remainderStateTimeMap\"\n",
    "PREPARED = \"PREPARED\"\n",
    "PREPREPARED = \"PREPREPARED\"\n",
    "COMMIT = \"COMMIT\"\n",
    "SYNC = \"SYNC\"\n",
    "ROUND_CHANGE = \"ROUND_CHANGE\"\n",
    "TOTAL_TIME_KEY = \"t_total_fastest\"\n",
    "RC_PROB = \"RC_PROB\"\n",
    "NEW_ROUND = \"NEW_ROUND\"\n",
    "PRE_PREPARED = \"PRE_PREPARED\"\n",
    "LAMBDA_FASTEST = \"lambda_fastest\"\n",
    "L_FASTEST = \"L_fastest\"\n",
    "L_REMAINDER = \"L_remainder\"\n",
    "\n",
    "NEW_VIEW = \"NEW_VIEW\"\n",
    "PREPARE = \"PREPARE\"\n",
    "PRE_COMMIT = \"PRE_COMMIT\"\n",
    "DECIDE = \"DECIDE\"\n",
    "COMMIT = \"COMMIT\"\n",
    "\n",
    "IBFT_STATES = [NEW_ROUND, PRE_PREPARED, PREPARED, ROUND_CHANGE]\n",
    "HS_STATES = [PREPARE, PRE_COMMIT, COMMIT, DECIDE]\n",
    "PROTOCOL_NAME_STATE_MAP = {\"hs\": HS_STATES, \"ibft\": IBFT_STATES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_num_faults = [0, 1, 2, 3]\n",
    "def get_num_faults_data(num_faults: int, name: str) -> pd.Series:\n",
    "    results_lst = os.listdir(\"results/\")\n",
    "    jsons = []\n",
    "    index = []\n",
    "    t_total = []\n",
    "    states = PROTOCOL_NAME_STATE_MAP[consensus_protocol.lower()] \n",
    "    fastest_state_times = {state : [] for state in states}\n",
    "    remainder_state_times = {state : [] for state in states}\n",
    "    fastest_message_arrival_rates = []\n",
    "\n",
    "    fastest_message_queue_lengths = []\n",
    "    remainder_message_queue_lengths = []\n",
    "    for result_filename in results_lst:\n",
    "        matcher = re.match(RESULTS_FOLDER_REGEX, result_filename)\n",
    "        if matcher == None: \n",
    "            continue\n",
    "        run_num_nodes = get_num_nodes(result_filename) \n",
    "        run_base_time_limit = get_btl(result_filename) \n",
    "        run_topology = get_topology(result_filename) \n",
    "        run_protocol = get_protocol(result_filename) \n",
    "        run_num_faults = get_num_faults(result_filename)\n",
    "        run_dist = get_node_distribution(result_filename)\n",
    " \n",
    "        if run_protocol != consensus_protocol.lower() or run_num_nodes != num_nodes or run_num_faults != num_faults or run_dist != node_processing_distribution:\n",
    "            continue\n",
    " \n",
    "        index.append(run_base_time_limit)\n",
    "        with open(os.path.join(RESULTS_FOLDER, result_filename, RESULTS_VALIDATOR_FILENAME), \"r\") as json_result:\n",
    "            result_json = json.load(json_result)\n",
    "            jsons.append(result_json)\n",
    "            t_total.append(result_json[TOTAL_TIME_KEY])\n",
    "            fastest_message_arrival_rates.append(result_json[LAMBDA_FASTEST])\n",
    "            fastest_message_queue_lengths.append(result_json[L_FASTEST])\n",
    "            remainder_message_queue_lengths.append(result_json[L_REMAINDER])\n",
    "            for state in states:\n",
    "                fastest_state_times[state].append(result_json[FASTEST_TIME_MAP][state])\n",
    "                remainder_state_times[state].append(result_json[REMAINDER_TIME_MAP][state])\n",
    "\n",
    "    return pd.Series(t_total, name=name, index=index)\n",
    "\n",
    "df = pd.DataFrame({\"0_fault\": get_num_faults_data(0, \"0_fault\"), \"1_fault\": get_num_faults_data(1, \"1_fault\"), \"2_fault\": get_num_faults_data(2, \"0_fault\"), \n",
    "                   \"3_fault\": get_num_faults_data(3, \"3_fault\")})\n",
    "df = df.sort_index().interpolate(method=\"linear\")\n",
    "df.plot(grid=True, style=\".-\", xlabel=\"base_time_limit\", ylabel=\"time_to_consensus\", title=consensus_protocol + \" simulation\")\n",
    "plt.show()\n",
    "# df = pd.DataFrame(fastest_state_times, index=index)\n",
    "# # df[\"t_total\"] = t_total\n",
    "# # df.sort_index(inplace=True)\n",
    "# # df.plot(grid=True, style=\".-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd495c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hs_time(n, t, mu, te2e):\n",
    "    max_f = (n - 1) // 3\n",
    "    p = gamma.cdf(t, 4 * n + 3 - max_f, scale=(1/mu))\n",
    "    # print(p)\n",
    "    t_fail = (1 - p) * t \n",
    "    # p2 = gamma.cdf(2 * t, 4 * n + 3  - max_f, scale=(1/mu))\n",
    "    # t_fail += (1 - p) * (1 - p2) * (2 * t)\n",
    "    t_succeed = 1 * te2e\n",
    "    # p3 = gamma.cdf(4 * t, 4 * n + 3 - f, scale=(1/mu))\n",
    "    # t_fail += (1 - p) * (1 - p2) * (1 - p3) * (4 * t)\n",
    "    t_total = t_fail + t_succeed\n",
    "    return t_total\n",
    "\n",
    "def hs_time_fault(n, t, rate, f):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = (4 * n + 4 - max_f - 3 * f) \n",
    "    te2e = m / rate \n",
    "\n",
    "    p_fault = f / n\n",
    "    t_penalty_first_fault = 0 \n",
    "    for i in range(1, f + 1):\n",
    "        t_penalty_first_fault += p_fault ** i * t * (2 ** (i - 1)) \n",
    "\n",
    "    p = gamma.cdf(t, m - 1, scale=(1/rate))\n",
    "    t_fail = (1 - p) * (t + t_penalty_first_fault * 2)\n",
    "    t_total = t_fail * (n - f) / n + te2e \n",
    "\n",
    "    # print(t_total, t_fail, t_succeed, t_penalty_first_fault)\n",
    "    return t_total + t_penalty_first_fault\n",
    "\n",
    "df[\"prediction\"] = df.index.map(lambda t: hs_time_fault(num_nodes, t, node_processing_parameters[0], num_faults))\n",
    "# df[\"prediction\"] = df.index.map(lambda t: full_estimate(num_nodes, num_faults, 1/3, 1/3, t))\n",
    "df.plot(style=\".-\", figsize=(10, 5), grid=True, xlabel=\"base_time_limit\", ylabel=\"time per consensus\")\n",
    "# Testing recommendation\n",
    "def hs_reco(n, f, mu, sigma):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    sigma_m = np.sqrt(m) * sigma \n",
    "    return (m * mu + 3 * sigma_m) \n",
    "\n",
    "test_num_nodes = [16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "test_mu = 1 / 3\n",
    "test_num_faults = [2]\n",
    "\n",
    "def range_max_estimate(n, mu):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f \n",
    "    return int(m * mu * 1.75)\n",
    "\n",
    "def range_min_estimate(n, mu):\n",
    "    # return int(range_max_estimate(n, mu) / 1.75 / 2)\n",
    "    return 0\n",
    "\n",
    "def get_minima(n, mu, frac):\n",
    "    max_f = (n - 1) // 3\n",
    "    f = int(frac * max_f)\n",
    "    top = range_max_estimate(n, mu)\n",
    "    bot = range_min_estimate(n, mu)\n",
    "    if frac == 0:\n",
    "        return hs_time_fault(n, top, 1/mu, f) \n",
    "    rg = [bot + (top - bot) / 1000 * i for i in range(1000)] \n",
    "    lst = [hs_time_fault(n, t, 1/mu, max_f * frac // 2) for t in rg] \n",
    "    s = pd.Series(lst, index=rg)\n",
    "    temp = s[(s < s.shift(1)) & (s < s.shift(-1))]\n",
    "    return temp.iloc[0]\n",
    "\n",
    "def get_num_faults_from_frac(n, frac):\n",
    "    return int((n - 1) // 3 * frac / 2)\n",
    "\n",
    "def hs_estimate_left_line(n, f, mu, t):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    te2e = m * mu\n",
    "    # gradient = n / (n - 2 * f) \n",
    "    # return te2e + gradient * t\n",
    "    one = te2e + sum((f / n) ** (i - 1) * t * 2 ** (i - 1) for i in range(1, f + 1))\n",
    "    one *= f / n\n",
    "    two = te2e + sum((f / n) ** i * (t * 2 ** i) for i in range(f + 1))\n",
    "    two *= (n - f) / n\n",
    "    return one + two\n",
    "\n",
    "\n",
    "def hs_estimate_right_line(n, f, mu, t):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    mean = m * mu\n",
    "    gradient = f / (n - 2 * f)\n",
    "    return mean + gradient * t\n",
    "\n",
    "def full_estimate(n, f, mu, sigma, t):\n",
    "    max_f = (n - 1) // 3\n",
    "    m = 4 * n - max_f - 3 * f\n",
    "    mean = m * mu\n",
    "    sigma_m = np.sqrt(m) * sigma\n",
    "    bot_boundary = mean - 2 * sigma_m\n",
    "    top_boundary = mean + 2 * sigma_m\n",
    "    y1 = hs_estimate_left_line(n, f, mu, bot_boundary)\n",
    "    y2 = hs_estimate_right_line(n, f, mu, top_boundary)\n",
    "    if t > top_boundary:\n",
    "        return hs_estimate_right_line(n, f, mu, t)\n",
    "    elif t < bot_boundary:\n",
    "        return hs_estimate_left_line(n, f, mu, t)\n",
    "    else:\n",
    "        gradient = (y2 - y1) / (top_boundary - bot_boundary)\n",
    "        intercept = y2 - gradient * top_boundary\n",
    "        return gradient * t + intercept\n",
    "\n",
    "\n",
    "# dic_model = {j: [get_minima(n, test_mu, j) for n in test_num_nodes] for j in test_num_faults}\n",
    "# dic_guess = {j: [hs_time_fault(n, hs_reco(n, get_num_faults_from_frac(n, j), test_mu, test_mu), 1/test_mu, get_num_faults_from_frac(n, j)) \n",
    "#                  for n in test_num_nodes] for j in test_num_faults}\n",
    "# df_model = pd.DataFrame(dic_model, index=test_num_nodes)\n",
    "# df_guess = pd.DataFrame(dic_guess, index=test_num_nodes)\n",
    "# (df_guess - df_model) / df_model\n",
    "\n",
    "plot_num_nodes = 2048\n",
    "rg = range(range_min_estimate(plot_num_nodes, test_mu), range_max_estimate(plot_num_nodes, test_mu))\n",
    "dic = {str(plot_num_nodes) + \"_\" + str(j): [hs_time_fault(plot_num_nodes, t, 1/test_mu, get_num_faults_from_frac(plot_num_nodes, j)) \n",
    "                               for t in range(range_min_estimate(plot_num_nodes, test_mu), range_max_estimate(plot_num_nodes, test_mu))]\n",
    "                               for j in test_num_faults}\n",
    "dic[\"test\"] = [full_estimate(plot_num_nodes, get_num_faults_from_frac(plot_num_nodes, 2), test_mu, test_mu, t) for t in rg]\n",
    "pd.DataFrame(dic, index=rg).plot( figsize=(15, 10), grid=True, ylabel=\"time to consensus\", xlabel=\"base time limit\")\n",
    "[plt.axvline(hs_reco(plot_num_nodes, get_num_faults_from_frac(plot_num_nodes, f), test_mu, test_mu)) for f in test_num_faults]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IBFT WORK DO NOT TOUCH\n",
    "round_change_probs = np.array(map(lambda dic: min(dic[FASTEST_MESSAGE_MAP][PREPREPARED] - 1, 1), jsons))\n",
    "consensus_times = np.array(map(lambda dic: dic[TOTAL_TIME_KEY], jsons))\n",
    "\n",
    "dic = {RC_PROB: round_change_probs, TOTAL_TIME_KEY: consensus_times, ROUND_CHANGE: fastest_state_times[ROUND_CHANGE], \"COMBINED\": fastest_state_times[\"COMBINED\"],\"z_value\": ((np.array(index) - 10) / 2.5)}\n",
    "\n",
    "df = pd.DataFrame(dic, index=index)\n",
    "df.sort_index(inplace=True)\n",
    "df[\"RC_PROB\"].plot(style=\".-\", grid=True, xlabel=\"base time limit\", ylabel=\"probability of round change\")\n",
    "df[\"z_value\"].apply(lambda x: 1 - norm.cdf(x)).plot()\n",
    "###\n",
    "def time3(t):\n",
    "    def helper(t, message_penalty):\n",
    "        if t >= 20:\n",
    "            return 12 \n",
    "        elif t <= 4:\n",
    "            return t + helper(2 * t, max(0, message_penalty - int(t * 3)) + 16)\n",
    "        p = norm.cdf((t - message_penalty / 3 - 10) / 2.5)\n",
    "        return (1 - p) * (8 + t + helper(2 * t, 5)) + p * min(12, t)\n",
    "    return helper(t, 0) - 2.7 + calc(t, 3)\n",
    "\n",
    "###\n",
    "# pd.Series(range(1, 40)).map(time3).plot()\n",
    "df[\"prediction\"] = df.index.map(time3)\n",
    "df[[TOTAL_TIME_KEY, \"prediction\"]].plot(grid=True, style=\".-\")\n",
    "\n",
    "### break\n",
    "rho = 2.67 / 3\n",
    "def pi(i):\n",
    "    return (1 - rho) * pow(rho, i)\n",
    "\n",
    "def calc(t, processing_rate):\n",
    "    i = 0\n",
    "    E = 0\n",
    "    cdf = 0\n",
    "    while i / processing_rate <= t:\n",
    "        E += (i / processing_rate) * pi(i)\n",
    "        cdf += pi(i)\n",
    "        i += 1\n",
    "    E += (1 - cdf) * t \n",
    "    p = (1 - norm.cdf((t - 12)))\n",
    "    p2 = 4 * p / 16\n",
    "    E = E * (1 - p2) + p2 * t\n",
    "    return E\n",
    "\n",
    "pd.DataFrame({ROUND_CHANGE: fastest_state_times[NEW_ROUND], \"TEST\": map(lambda x : calc(x, 3), index)}, index=index).sort_index().plot(grid=True, style=\".-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
